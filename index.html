<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Hongyue Wang</title>

    <meta name="author" content="Hongyue Wang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Hongyue Wang „ÄåÁéãÈ∏øÂ≤≥„Äç
                </p>
                <p style="text-align:justify">
		I am a 2nd-year Ph.D. candidate in¬†<a href="https://exertiongameslab.org/">exertion games lab</a>¬†supervised by Prof.¬†<a href="https://www.florianfloydmueller.com/">Florian 'Floyd' Mueller</a>¬†working on Human-Food Interaction (Secondary Supervisor: Dr.¬†<a href="https://samithaelvitigala.com/">Don Samitha Elvitigala</a>) at Monash University, Australia.
		</p>
		      
                <p style="text-align:center">
                  <a href="mailto:hongyue@exertiongameslab.org">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=kXGKhaMAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/hongyuewang_">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/hongyuewanghci">LinkedIn</a>
                </p>
		      	      
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/why.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/why.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

           <h2>My research interests</h2>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <p>My research explores the intersection of human-computer interaction and creative practice, focusing on designing interactive systems that reveal how emerging technologies can open up new possibilities in creative practitioners' workflows. I am particularly interested in the following areas: 
		<ul>
		<li>Developing human-centered creativity support systems via Human-AI co-creation;</li>
		  <li>Exploring bold and avant-garde edible interfaces that merge technology, art, and interaction to reimagine the future of eating experiences.</li>
		</ul>
		</p>
             	<p>I am a Research through Design (RtD) practitioner who places strong emphasis on user experience. My work is grounded in hands-on design practice, iterative experimentation, and close engagement with participants ‚Äî through which I aim to generate situated, practice-based knowledge for the HCI community.</p>
		<p>Recently, I have been exploring interactive sound as a programmable and orchestratable "ingredient" that supports culinary practitioners in their creative experimentation, thereby enriching the dining experience. I am also dedicated to meaningfully integrating digital content into our everyday eating.</p>      
	      </td>
            </tr>
		<tr>
			<td style="padding:16px;width:100%;vertical-align:middle">
                	<h2>News</h2>
               		 <ul>
			<li><p style="text-align:justify"><b>01/2025:</b> We got two CHI papers accepted in the main track and also with two LBWs!! See you all in Yokohama!! üéâ</p></li>
			<li><p style="text-align:justify"><b>03/2024:</b> Our two ACM CHI 2024 late-breaking works have been accepted!! Thanks to all the co-authors!! üòä</p></li>
			</ul>
			</td>
		</tr>
          </tbody>
	  </table>

	<h2>Full Paper Publications</h2>			
	<table style="width:100%;border:2px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>    
	<tr>
		<td style="padding:8px;width:100%; vertical-align:middle">
	        <a href="https://doi.org/10.1145/3706598.3714237">
	          <span class="papertitle">Towards Understanding Interactive Sonic Gastronomy with Chefs and Diners</span>
	        </a>
	        <br><strong>Hongyue Wang</strong>, Jialin Deng, Linjia He, Nathalie Overdevest, Ryan Wee, Yan Wang, Phoebe O. Toups Dugas, Don Samitha Elvitigala, Florian 'Floyd' Mueller
	        <br>
	        <em>ACM Conference on Human Factors in Computing Systems <strong>(CHI 2025)</strong></em>
	        <br>
	        <a href="/file/towards2025.pdf" target="_blank">[Paper]</a>
		</td>
	</tr>

	<tr>
		<td style="padding:8px;width:100%; vertical-align:middle">
	        <a href="https://doi.org/10.1145/3706598.3713892">
	          <span class="papertitle">Sonic Delights: Exploring the Design of Food as An Auditory-Gustatory Interface</span>
	        </a>
	        <br>Jialin Deng, Yinyi Li, <strong>Hongyue Wang</strong>, Ziqi Fang, Florian 'Floyd' Mueller
	        <br>
	        <em>ACM Conference on Human Factors in Computing Systems <strong>(CHI 2025)</strong></em>
	        <br>
	        <a href="/file/sonicdelights.pdf" target="_blank">[Paper]</a>
		</td>
	</tr>
		
	<tr>
		<td style="padding:8px;width:100%; vertical-align:middle">
	        <a href="https://www.sciencedirect.com/science/article/pii/S1071581923002069">
	          <span class="papertitle">Grand challenges in human-food interaction</span>
	        </a>
	        <br>Florian ‚ÄòFloyd‚Äô Mueller, Marianna Obrist, Ferran Altarriba Bertran, Neharika Makam, Soh Kim, Christopher Dawes, Patrizia Marti, Maurizio Mancini, Eleonora Ceccaldi, Nandini Pasumarthy, Sahej Claire, Kyung seo Jung, Jialin Deng, J√ºrgen Steimle, Nadejda Krasteva, Matti Schwalk, Harald Reiterer, <strong>Hongyue Wang</strong>, Yan Wang
	        <br>
	        <em>International Journal of Human-Computer Studies</em>, 2024
	        <br>
	        <a href="/file/grand challenges.pdf" target="_blank">[Paper]</a>
		</td>
	</tr>

	<tr>		
	      <td style="padding:8px;width:100%; vertical-align:middle">
	        <a href="https://www.tandfonline.com/doi/abs/10.1080/10447318.2023.2227823">
	          <span class="papertitle">MRLab: Virtual Reality Fusion Smart Laboratory Based on Multimodal Fusion</span>
	        </a>
	        <br><strong>Hongyue Wang</strong>, Zhiquan Feng*, Xiaohui Yang, Liran Zhou, Jinglan Tian, Qingbei Guo<br>
	        <em>International Journal of Human-Computer Interaction</em>, 2023
	        <br>
	        <a href="/file/MRLab.pdf" target="_blank">[Paper]</a>
	      </td>	
	</tr>

	<tr>		
	      <td style="padding:8px;vertical-align:middle">
	        <a href="https://www.tandfonline.com/doi/abs/10.1080/10447318.2023.2247606?journalCode=hihc20">
	          <span class="papertitle">MIUIC: A Human-Computer Collaborative Multimodal Intention-Understanding Algorithm Incorporating Comfort Analysis</span>
	        </a>
	        <br>Liran Zhou, Zhiquan Feng*, <strong>Hongyue Wang</strong>, Qingbei Guo<br>
	        <em>International Journal of Human-Computer Interaction</em>, 2023
	        <br>
	        <a href="/file/MIUIC.pdf" target="_blank">[Paper]</a>
	      </td>	
	</tr>

	<tr>
	      <td style="padding:8px;vertical-align:middle">
	        <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/admt.202200549">
	          <span class="papertitle">Multimodal Information Perception and Understanding: Application of Smart Glove in Virtual-Reality Fusion Chemistry Experiment Platform</span>
	        </a>
	        <br><strong>Hongyue Wang</strong>, Zhiquan Feng*, Xin Meng<br>
	        <em>Advanced Materials Technologies</em>, 2023
	        <br>
	        <a href="/file/Multimodal Information Perception and UnderstandingÔºöApplication of Smart Glove in Virtual-Reality Fusion Chemistry Experiment Platform.pdf" target="_blank">[Paper]</a>
	      <a href="https://youtu.be/8btwYEO1cd4" target="_blank">[Video]</a></td>
	      </td>	
	</tr>

	<tr>
	      <td style="padding:8px;vertical-align:middle">
	        <a href="https://www.hindawi.com/journals/cin/2022/3545850/">
	          <span class="papertitle">MFA: A Smart Glove with Multimodal Intent Sensing Capability</span>
	        </a>
	        <br><strong>Hongyue Wang</strong>, Zhiquan Feng*, Jinglan Tian, Xue Fan<br>
	        <em>Computational Intelligence and Neuroscience</em>, 2022
	        <br>
	        <a href="/file/MFA.pdf" target="_blank">[Paper]</a>
	      </td>	
	</tr>

	<tr>
	      <td style="padding:8px;vertical-align:middle">
	        <a href="https://link.springer.com/chapter/10.1007/978-981-19-4546-5_32">
	          <span class="papertitle">Research on the Structure and Key Algorithms of Smart Gloves Oriented to Middle School Experimental Scene Perception</span>
	        </a>
	        <br><strong>Hongyue Wang</strong>, Xin Meng, Zhiquan Feng*<br>
	        <em>ChineseCSCW '21: Computer Supported Cooperative Work and Social Computing</em>
	        <br>
	        <a href="/file/Research on the Structure and Key Algorithms of Smart Gloves Oriented to Middle School Experimental Scene Perception.pdf" target="_blank">[Paper]</a>
	      </td>	
	</tr>
          </tbody></table>

	  
	<h2>Workshop Papers, Extended Abstracts, and Doctoral Consortium</h2>		
	<table style="width:100%;border:2px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> 	

	<tr>
	      <td style="padding:8px;vertical-align:middle">
	        <a href="https://doi.org/10.1145/3706599.3719700">
	          <span class="papertitle">GastroConcerto: Towards Designing Auditory Dining System to Enrich Chefs‚Äô Culinary Practices</span>
	        </a>
	        <br><strong>Hongyue Wang</strong>, Jialin Deng, Dehui Kong, Ziqi Fang, Hong Luo, Nandini Pasumarthy, Rakesh Patibanda, Sasindu Abewickrema, Xiao 'Zoe' Fang, Don Samitha Elvitigala, Florian 'Floyd' Mueller<br>
	        <em>ACM Conference on Human Factors in Computing Systems <strong>(CHI 2025 Late Breaking Work)</strong></em>
	        <br>
	        <a href="/file/gastro.pdf" target="_blank">[Paper]</a>
		<a href="https://www.youtube.com/watch?v=d0GZcocqnV0" target="_blank">[Video]</a>
	      </td>	
	</tr>
		
	<tr>
	      <td style="padding:8px;vertical-align:middle">
	        <a href="x">
	          <span class="papertitle">immersiTea: Exploring Multisensory Virtual Reality Environments to Enrich Bubble Tea Drinking Experiences</span>
	        </a>
	        <br>Yuchen Zheng, Jialin Deng, <strong>Hongyue Wang</strong>, Florian 'Floyd' Mueller, Xueni Pan, Marco Fyfe Pietro Gillies<br>
	        <em>ACM Conference on Human Factors in Computing Systems <strong>(CHI 2025 Late Breaking Work)</strong></em>
	        <br>
	        <a href="/file/milktea.pdf" target="_blank">[Paper]</a>
		<a href="x" target="_blank">[Video]</a>
	      </td>	
	</tr>		
	<tr>
	      <td style="padding:8px;vertical-align:middle">
	        <a href="https://doi.org/10.1145/3613905.3651082">
	          <span class="papertitle">pic2eat: Facilitating Social Ice-breaking through Collaborative Design of 3D Printed Appetizer</span>
	        </a>
	        <br><strong>Hongyue Wang</strong>, Jialin Deng, Aravind Mohan, Yinyi Li, Hao Peng, Linjia He, Don Samitha Elvitigala, Florian 'Floyd' Mueller<br>
	        <em>ACM Conference on Human Factors in Computing Systems <strong>(CHI 2024 Late Breaking Work)</strong></em>
	        <br>
	        <a href="/file/pic2eat.pdf" target="_blank">[Paper]</a>
		<a href="https://www.youtube.com/watch?v=d0GZcocqnV0" target="_blank">[Video]</a>
	      </td>	
	</tr>

	<tr>
	      <td style="padding:8px;vertical-align:middle">
	        <a href="https://dl.acm.org/doi/10.1145/3613905.3650789">
	          <span class="papertitle">PenLab: Towards Understanding of Active Collaboration for Solid Geometry Teaching</span>
	        </a>
	        <br>Dehui Kong, <strong>Hongyue Wang</strong>, Sijie Zhou, Hong Cui, Zhiquan Feng<br>
	        <em>ACM Conference on Human Factors in Computing Systems <strong>(CHI 2024 Late Breaking Work)</strong></em>
	        <br>
	        <a href="/file/penlab.pdf" target="_blank">[Paper]</a>
		<a href="https://www.youtube.com/watch?v=KzXrsdY8Xhw" target="_blank">[Video]</a>
	      </td>	
	</tr>

	<tr>
	      <td style="padding:8px;vertical-align:middle">
	        <a href="https://dl.acm.org/doi/abs/10.1145/3656156.3663699">
	          <span class="papertitle">Pedalling into the Future: Towards Enhancing Cycling Experience Using Augmented Reality</span>
	        </a>
	        <br>Linjia He, <strong>Hongyue Wang</strong>, Sarah Goodwin, Benjamin Tag, Don Samitha Elvitigala<br>
	        <em>ACM Designing Interactive Systems Conference <strong>(DIS 2024 Extended Abstract)</strong>
	        <br>
	        <a href="/file/Pedalling into the Future.pdf" target="_blank">[Paper]</a>
	      </td>	
	</tr>
	</tbody></table>

          
	<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Academic Service</h2>
              </td>
            </tr>
		
	<tr>
		<td style="padding:16px;width:100%;vertical-align:middle">
		<ul>
		<li><p style="text-align:justify"><b>2025: </b>CHI 2025 Late Breaking Work Associate Chair; Paper reviewer (CHI 2025)</p></li>
		<li><p style="text-align:justify"><b>2024: </b>Paper reviewer (IJHCI, DIS 2024, CHI 2024 Late-breaking work)</p></li>
		</ul>
		</td>
	</tr>
          </tbody></table>

	  
         
		
        </td>
      </tr>
    </table>
	  <div style="text-align: center; padding: 20px 0;">
  <a href='https://clustrmaps.com/site/1c5b3'  title='Visit tracker'>
    <img src='//clustrmaps.com/map_v2.png?cl=080808&w=a&t=n&d=WURmUG8z_l1BDMsm0g2NXz5vFJwtmfGpJyvvc32pLNs&co=ffffff&ct=808080'/>
  </a>
</div>

  </body>
</html>
